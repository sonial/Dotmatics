{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#install the required libaries\n",
    "\n",
    "!pip install git+ssh://git@github.com/healx/healx-chem.git && pip install git+ssh://git@github.com/healx/healx-python.git#egg=healx && pip insyall healx[graphql]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from healx.graphql_client import client\n",
    "from healx_chem import CompoundSpace\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "\"\"\"load_dotenv(verbose = True)\n",
    "\n",
    "# Access the environment variables\n",
    "eee = os.getenv('GRAPHQL_API_URL')\n",
    "os.getenv('GRAPHQL_API_CLIENT')\n",
    "os.getenv('GRAPHQL_API_KEY')\"\"\"\n",
    "\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Explicitly specify the path to the .env file\n",
    "dotenv_path = os.path.join(os.getcwd(), 'settings.env')\n",
    "\n",
    "# Check if the .env file exists at the specified path\n",
    "if os.path.exists(dotenv_path):\n",
    "    print(f\"settings.env file found at: {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"settings.env file not found at: {dotenv_path}\")\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path, verbose=True)\n",
    "\n",
    "# Access the environment variables\n",
    "url = os.getenv('GRAPHQL_API_URL')\n",
    "db_username = os.getenv('GRAPHQL_API_CLIENT')\n",
    "db_password = os.getenv('GRAPHQL_API_KEY')\n",
    "\n",
    "if url and db_username and db_password:\n",
    "    print(\"Credentials loaded successfully\")\n",
    "else:\n",
    "    print(\"Failed to load credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tautomer parent SMILES for all compounds in KB\n",
    "def fetch_smiles_KB():\n",
    "    query = \"\"\"{\n",
    "      compounds{\n",
    "        name\n",
    "        primaryForm{\n",
    "          standardisedStructures{\n",
    "            tautomerParentSmiles\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\"\"\"\n",
    "    compounds = client(query)[\"compounds\"]\n",
    "    return compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBcompounds = fetch_smiles_KB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBcompounds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBsmiles = {}\n",
    "multiple_parents = []\n",
    "for dic in KBcompounds:\n",
    "    for key, value in dic.items():\n",
    "        smiles_list = []\n",
    "        if key == \"name\":\n",
    "            name = value\n",
    "        if key == \"primaryForm\":\n",
    "            for k, v in value.items():\n",
    "                if len(v)>=1:\n",
    "                    for i in v:\n",
    "                        for taut, smiles in i.items():\n",
    "                            if smiles not in smiles_list:\n",
    "                                smiles_list.append(smiles)\n",
    "# get list of compounds with multiple tautomer parent structures       \n",
    "        if len(smiles_list)>1:\n",
    "            temp_dic = {}\n",
    "            temp_dic[name]=smiles_list\n",
    "            multiple_parents.append(temp_dic)\n",
    "# retain only compound name and first tautomer parent smiles\n",
    "        if len(smiles_list):\n",
    "            KBsmiles[name] = smiles_list[0]\n",
    "\n",
    "print(len(KBsmiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(multiple_parents))\n",
    "print(multiple_parents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CompoundSpace(KBsmiles)\n",
    "cs.calculate_fingerprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ID, name and structure for Dotmatics compound not mapping to KB\n",
    "# Open the CSV file\n",
    "with open(\"/Users/sonialiggi/Library/CloudStorage/GoogleDrive-sonia.liggi@healx.io/Shared drives/Internal Projects/Dotmatics/KB Mapping/NotMapping.csv\", \"r\") as csvfile:\n",
    "    # Create a CSV reader object\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    # Skip the header row (optional)\n",
    "    next(reader)\n",
    "\n",
    "    # Create an empty dictionary\n",
    "    data_dict = {}\n",
    "\n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Get the values from the columns\n",
    "        ID = row[0]\n",
    "        name = row[1]\n",
    "        smi = row[2]\n",
    "        data_dict[ID] = [name, smi]\n",
    "    \n",
    "# Print the dictionary\n",
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pp = cs.search(query=data_dict['HLX0001904'][1])\n",
    "filtered_matrix =pp.reset_index().rename(columns={\"index\": \"KB_name\", \"ref\": \"similarity_score\"})\n",
    "filtered_matrix[\"DotmaticsID\"] = \"HLX0001904\"\n",
    "\n",
    "filtered_matrix[\"Dotmatics_smiles\"] = data_dict[\"HLX0001904\"][1]\n",
    "filtered_matrix[\"KB_smiles\"] = filtered_matrix[\"KB_name\"].map(KBsmiles)\n",
    "filtered_matrix[\"Dotmatics_name\"] = data_dict[\"HLX0001904\"][0]\n",
    "filtered_matrix = filtered_matrix[[\"DotmaticsID\", \"Dotmatics_name\", \"Dotmatics_smiles\", \"KB_name\", \"KB_smiles\", \"similarity_score\"]]\n",
    "cond1 = filtered_matrix[\"KB_name\"] == \"SULFINPYRAZONE\"\n",
    "cond2 = filtered_matrix[\"similarity_score\"] == filtered_matrix[\"similarity_score\"].max()\n",
    "filtered_matrix = filtered_matrix[cond1 | cond2]\n",
    "filtered_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run similarity search\n",
    "dataframes = []\n",
    "c = 1\n",
    "for id, llist in data_dict.items():\n",
    "    query_smiles = llist[1]\n",
    "    sim_matrix = cs.search(query=query_smiles)\n",
    "    filtered_matrix = sim_matrix[sim_matrix[\"ref\"] == sim_matrix[\"ref\"].max()]\n",
    "    filtered_matrix = filtered_matrix.reset_index().rename(columns={\"index\": \"KB_name\", \"ref\": \"similarity_score\"})\n",
    "    filtered_matrix[\"DotmaticsID\"] = id\n",
    "    filtered_matrix[\"index\"] = c\n",
    "    filtered_matrix[\"Dotmatics_smiles\"] = llist[1]\n",
    "    filtered_matrix[\"KB_smiles\"] = filtered_matrix[\"KB_name\"].map(KBsmiles)\n",
    "    filtered_matrix[\"Dotmatics_name\"] = data_dict[id][0]\n",
    "    filtered_matrix = filtered_matrix[[\"index\", \"DotmaticsID\", \"Dotmatics_name\", \"Dotmatics_smiles\", \"KB_name\", \"KB_smiles\", \"similarity_score\"]]\n",
    "    dataframes.append(filtered_matrix)\n",
    "    c +=1\n",
    "result_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"/Users/sonialiggi/Library/CloudStorage/GoogleDrive-sonia.liggi@healx.io/Shared drives/Internal Projects/Dotmatics/KB Mapping/NotMapping_KBsimilarity.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dotmatics2KB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
